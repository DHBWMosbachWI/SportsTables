{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Web-Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-11T10:36:40.417323Z",
     "end_time": "2023-05-11T10:37:47.105586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n",
      "not possible\n"
     ]
    }
   ],
   "source": [
    "### extract all soccer data\n",
    "\n",
    "# code für die player stats - scraped nur eine seite, wie im alten code\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import os\n",
    "from os.path import join\n",
    "import time\n",
    "\n",
    "from web_scraping import get_soccer_leagues_ids, get_soccer_league_season_standings, get_soccer_teams_url, get_player_season_stats2\n",
    "\n",
    "current_season = 2022\n",
    "soccer_league_ids = get_soccer_leagues_ids()\n",
    "\n",
    "for year in range(1999,2000):\n",
    "    print(year)\n",
    "    try:\n",
    "        for soccer_league_id in soccer_league_ids:\n",
    "            if soccer_league_id[\"league_name\"] == \"Fußball-Bundesliga\" or soccer_league_id[\"league_name\"] == \"Big 5 European Leagues Combined\":\n",
    "                continue\n",
    "\n",
    "            # get player stats\n",
    "            df = get_player_season_stats2(year, current_season, soccer_league_id[\"league_id\"], soccer_league_id[\"league_stats_name\"])\n",
    "            df.to_csv(join(os.environ[\"SportsTables\"], \"soccer\", f\"{soccer_league_id['league_name'].replace(' ','-')}_player_stats_{year}.csv\"), index=False)\n",
    "\n",
    "            time.sleep(3)\n",
    "    except:\n",
    "        print(\"not possible\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPConnectionPool(host='localhost', port=58990): Max retries exceeded with url: /session/f1884e1ee9f86d9ffc70c46bae8b753d/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F40DCF0340>: Failed to establish a new connection: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte'))\n",
      "HTTPConnectionPool(host='localhost', port=58990): Max retries exceeded with url: /session/f1884e1ee9f86d9ffc70c46bae8b753d/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F40B081400>: Failed to establish a new connection: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte'))\n",
      "HTTPConnectionPool(host='localhost', port=58990): Max retries exceeded with url: /session/f1884e1ee9f86d9ffc70c46bae8b753d/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F40B87CCD0>: Failed to establish a new connection: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# zeigt den Fehler, wenn alle Tabellen von den player stats geladen werden sollen\n",
    "\n",
    "from web_scraping import get_player_season_stats2, get_soccer_leagues_ids\n",
    "\n",
    "\n",
    "current_season = 2022\n",
    "soccer_league_ids = get_soccer_leagues_ids()\n",
    "\n",
    "for year in range(1999, 2000):\n",
    "    for soccer_league_id in soccer_league_ids:\n",
    "        try:\n",
    "            standings = get_player_season_stats2(year, current_season, soccer_league_id[\"league_id\"], soccer_league_id[\"league_stats_name\"])\n",
    "        except Exception as e:\n",
    "            if hasattr(e, 'message'):\n",
    "                print(e.message)\n",
    "            else:\n",
    "                print(e)\n",
    "\n",
    "        continue\n",
    "    #print(f\"Scraped {len(standings)} tables from {len(url)} pages.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T10:50:25.417334Z",
     "end_time": "2023-05-11T10:52:08.477619Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n",
      "https://fbref.com/en/squads/19538871/1999-2000/Manchester-United-Stats\n",
      "https://fbref.com/en/squads/18bb7c10/1999-2000/Arsenal-Stats\n",
      "https://fbref.com/en/squads/5bfb9659/1999-2000/Leeds-United-Stats\n",
      "https://fbref.com/en/squads/822bd0ba/1999-2000/Liverpool-Stats\n",
      "https://fbref.com/en/squads/cff3d9bb/1999-2000/Chelsea-Stats\n",
      "https://fbref.com/en/squads/8602292d/1999-2000/Aston-Villa-Stats\n",
      "https://fbref.com/en/squads/8ef52968/1999-2000/Sunderland-Stats\n",
      "https://fbref.com/en/squads/a2d435b3/1999-2000/Leicester-City-Stats\n",
      "https://fbref.com/en/squads/7c21e445/1999-2000/West-Ham-United-Stats\n",
      "https://fbref.com/en/squads/361ca564/1999-2000/Tottenham-Hotspur-Stats\n",
      "https://fbref.com/en/squads/b2b47a98/1999-2000/Newcastle-United-Stats\n",
      "https://fbref.com/en/squads/7f59c601/1999-2000/Middlesbrough-Stats\n",
      "https://fbref.com/en/squads/d3fd31cc/1999-2000/Everton-Stats\n",
      "https://fbref.com/en/squads/f7e3dfe9/1999-2000/Coventry-City-Stats\n",
      "https://fbref.com/en/squads/33c895d4/1999-2000/Southampton-Stats\n",
      "https://fbref.com/en/squads/26ab47ee/1999-2000/Derby-County-Stats\n",
      "https://fbref.com/en/squads/3148d79f/1999-2000/Bradford-City-Stats\n",
      "https://fbref.com/en/squads/3679c494/1999-2000/Wimbledon-Stats\n",
      "https://fbref.com/en/squads/bba7d733/1999-2000/Sheffield-Wednesday-Stats\n",
      "https://fbref.com/en/squads/2abfe087/1999-2000/Watford-Stats\n",
      "Saved Premier-League-Stats_stats_standard_9_1999-2000.csv\n",
      "Saved Premier-League-Stats_matchlogs_for_1999-2000.csv\n",
      "Saved Premier-League-Stats_stats_keeper_9_1999-2000.csv\n",
      "Saved Premier-League-Stats_stats_shooting_9_1999-2000.csv\n",
      "Saved Premier-League-Stats_stats_playing_time_9_1999-2000.csv\n",
      "Saved Premier-League-Stats_stats_misc_9_1999-2000.csv\n",
      "Saved Premier-League-Stats_results1999-200091_overall_1999-2000.csv\n",
      "Saved Premier-League-Stats_results1999-200091_home_away_1999-2000.csv\n",
      "not possible\n"
     ]
    }
   ],
   "source": [
    "### extract all soccer data\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import os\n",
    "from os.path import join\n",
    "import time\n",
    "\n",
    "from web_scraping import get_soccer_leagues_ids, get_soccer_league_season_standings, get_soccer_teams_url, get_player_season_stats\n",
    "\n",
    "current_season = 2022\n",
    "soccer_league_ids = get_soccer_leagues_ids()\n",
    "\n",
    "for year in range(1999,2000):\n",
    "    print(year)\n",
    "    try:\n",
    "        for soccer_league_id in soccer_league_ids:\n",
    "            if soccer_league_id[\"league_name\"] == \"Fußball-Bundesliga\" or soccer_league_id[\"league_name\"] == \"Big 5 European Leagues Combined\":\n",
    "                continue\n",
    "\n",
    "            # get player stats\n",
    "            df = get_player_season_stats(year, current_season, soccer_league_id[\"league_id\"], soccer_league_id[\"league_stats_name\"])\n",
    "            df.to_csv(join(os.environ[\"SportsTables\"], \"soccer\", f\"{soccer_league_id['league_name'].replace(' ','-')}_player_stats_{year}.csv\"), index=False)\n",
    "\n",
    "            time.sleep(3)\n",
    "    except:\n",
    "        print(\"not possible\")\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T12:18:19.004176Z",
     "end_time": "2023-05-11T12:21:51.495457Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# scraped all table data without getting httpconnectionpool error\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "\n",
    "leagues = {\n",
    "    'premier_league': list(range(1982, 2000)),\n",
    "    'ligue_1': list(range(1989, 2000)),\n",
    "    'serie_a': list(range(1994, 2000)),\n",
    "    'la_liga': list(range(1993, 2000))\n",
    "}\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "for league, years in leagues.items():\n",
    "    for year in years:\n",
    "        if league == 'premier_league':\n",
    "            url = f'https://fbref.com/en/comps/9/{year}-{year+1}/{year}-{year+1}-Premier-League-Stats'\n",
    "        elif league == 'ligue_1':\n",
    "            url = f'https://fbref.com/en/comps/13/{year}-{year+1}/{year}-{year+1}-Ligue-1-Stats'\n",
    "        elif league == 'serie_a':\n",
    "            url = f'https://fbref.com/en/comps/11/{year}-{year+1}/{year}-{year+1}-Serie-A-Stats'\n",
    "        elif league == 'la_liga':\n",
    "            url = f'https://fbref.com/en/comps/12/{year}-{year+1}/{year}-{year+1}-La-Liga-Stats'\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        try:\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            tables = soup.find_all('table')\n",
    "            for table in tables:\n",
    "                # extract the table id\n",
    "                table_id = table.get('id')\n",
    "                if table_id is not None:\n",
    "                    df = pd.read_html(str(table))[0]\n",
    "                    name = f'{league}_{table_id}.csv'\n",
    "                    df.to_csv(name, index=False)\n",
    "                    print(f'Saved {name}')\n",
    "\n",
    "        except:\n",
    "            print(\"not possible\")\n",
    "            pass\n",
    "\n",
    "# Close the browser session\n",
    "driver.quit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T19:01:25.364495Z",
     "end_time": "2023-05-10T19:04:28.952713Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract column headers from different tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-05T16:31:24.627542Z",
     "end_time": "2023-05-05T16:31:24.745434Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "metadata = {}\n",
    "\n",
    "tables = [\"player_stats\", \"season_standings\"]\n",
    "\n",
    "for table in tables:\n",
    "    column_names = []\n",
    "    for found_table in glob(join(os.environ[\"SportsTables\"], \"soccer\", f\"*{table}_*.csv\")):\n",
    "        column_names.extend(list(pd.read_csv(found_table).columns))\n",
    "    \n",
    "    column_names = list(set(column_names))\n",
    "    metadata[table] = {}\n",
    "    for column_name in column_names:\n",
    "        metadata[table][column_name] = None\n",
    "    \n",
    "if os.path.isfile(\"metadata.json\"):\n",
    "    print(\"metadata.json exists already!!! \")\n",
    "else:\n",
    "    with open(\"metadata.json\", \"w\") as f:\n",
    "        json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract valid header file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-04T22:29:45.919652Z",
     "end_time": "2023-05-04T22:29:45.934716Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "import os \n",
    "#os.environ[\"SPORTS_DB\"] = \"/ext/daten-wi/slangenecker/SportsTables\"\n",
    "os.environ[\"SPORTS_DB\"] = \"C:/Users/jwuel/DataspellProjects/SportsTables\"\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "\n",
    "def get_sportsDB_soccer_type_mappings():\n",
    "    with open(join(os.environ[\"SPORTS_DB\"], \"Soccer\", \"Soccer-Relations.json\"), \"r\") as f:\n",
    "        type_mappings = json.load(f)[\"soccer-big5Leagues-Players-2021-2022.csv\"][\"columns\"][0]\n",
    "        return type_mappings\n",
    "\n",
    "\n",
    "def get_all_sportsDB_soccer_tables(only_file_names:bool=False):\n",
    "    result = glob(join(os.environ[\"SPORTS_DB\"], \"Soccer\", \"soccerPlayerScraping\", \"*.csv\"))\n",
    "    if only_file_names:\n",
    "        return [table.split(\"/\")[-1] for table in result]\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "def load_sportsDB_soccer_table(table_name:str, only_headers:bool=False):\n",
    "    df = pd.read_csv(join(os.environ[\"SPORTS_DB\"], \"Soccer\", \"soccerPlayerScraping\", table_name))\n",
    "    if only_headers:\n",
    "        return df.columns\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_to_sem_type = get_sportsDB_soccer_type_mappings()\n",
    "\n",
    "results = {}\n",
    "for table in get_all_sportsDB_soccer_tables(True):\n",
    "    print(table)\n",
    "    results[table.split(\".csv\")[0]] = {}\n",
    "    col_names = load_sportsDB_soccer_table(table, True)\n",
    "    for col_num, col_name in enumerate(col_names):\n",
    "        try:\n",
    "            results[table.split(\".csv\")[0]][f\"column_{col_num}\"] = { \"semanticType\": col_name_to_sem_type[col_name]}\n",
    "        except:\n",
    "            print(col_name)\n",
    "    \n",
    "with open(join(os.environ[\"SPORTS_DB\"], \"Soccer\", \"sportsDB_type_sportsDB.json\"), \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
