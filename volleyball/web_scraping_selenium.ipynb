{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# scraped alle tabellen von der url\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument('headless')\n",
    "driver = webdriver.Edge(service=EdgeService(EdgeChromiumDriverManager().install()), options=options)\n",
    "\n",
    "years = range(2016, 2023)\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://www.volleyball-bundesliga.de/cms/home/1_bundesliga_maenner/archiv/statistikrankings/saison_{year}_{year + 1 - 2000}.xhtml'\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    html = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    for i, table in enumerate(tables):\n",
    "        h1_tag = table.find_previous('h1')\n",
    "        title = re.sub(r'[^\\w\\s-]', '', h1_tag.text.strip())\n",
    "        title = title.lower()\n",
    "        df = pd.read_html(str(table))[0]\n",
    "        filename = f'{title.replace(\" \", \"_\").replace(\"  \", \"_\")}_{year}_{year + 1}.csv'\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "driver.quit()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-18T18:24:41.426035Z",
     "end_time": "2023-06-18T18:25:36.525180Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 8.22M/8.22M [00:01<00:00, 6.63MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n"
     ]
    }
   ],
   "source": [
    "# funktioniert ABER\n",
    "    # erste Zeile wird nicht mitgenommen\n",
    "    # Formatierung der Datei ist falsch (komplette Zeile steht in einer Zelle)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import os\n",
    "from os.path import join\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument('headless')\n",
    "driver = webdriver.Edge(service=EdgeService(EdgeChromiumDriverManager().install()), options=options)\n",
    "\n",
    "from web_scraping import get_volleyball_league_scores\n",
    "\n",
    "years = range(2015, 2023)\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    df = get_volleyball_league_scores(year, driver)\n",
    "    df.to_csv(join(os.environ[\"SportsTables\"], \"volleyball\", f\"bundesliga_men_player_ranking_serve_{year}.csv\"), sep=',', index=False)\n",
    "\n",
    "driver.quit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-15T17:17:13.234034Z",
     "end_time": "2023-06-15T17:17:44.946116Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# scraped alle tabellen von der url\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "years = range(2015, 2023)\n",
    "\n",
    "for year in years:\n",
    "    url = f'https://www.volleyball-bundesliga.de/cms/home/1_bundesliga_frauen/archiv/statistikrankings/saison_{year}_{year + 1 - 2000}.xhtml'\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    html = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    for i, table in enumerate(tables):\n",
    "        h1_tag = table.find_previous('h1')\n",
    "        title = re.sub(r'[^\\w\\s-]', '', h1_tag.text.strip())\n",
    "        title = title.lower()\n",
    "        df = pd.read_html(str(table))[0]\n",
    "        filename = f'{title.replace(\" \", \"_\").replace(\"  \", \"_\")}_{year}_{year + 1}.csv'\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "driver.quit()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-12T21:06:59.750800Z",
     "end_time": "2023-06-12T21:08:14.387646Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
